---
title: "IES R Tutorial"
author: "Michael Chirico"
date: "Compiled `r format(Sys.time(), '%B %d, %Y at %R')`"
output: 
  rmarkdown::html_document:
    toc: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Overview

First and foremost is to install R (following instructions [here](http://lib.stat.cmu.edu/R/CRAN/)) so that your computer knows how to interpret R code. Then, I highly recommend you install RStudio (following instructions [here](https://www.rstudio.com/products/rstudio/download/)), which is a powerful program for organizing your interaction with the R language (a subtle distinction, and you wouldn't really be ill-served by considering RStudio and R to be the same thing); for the jargon-hungry, RStudio is an Integrated Development Environment (IDE) for the R language.

Some general guidelines for getting the most out of this workshop:

 1. **Active participation is key!** You should be running every snippet of code I go over on your own machine. As with human languages, exposure is one of the building blocks of fluency. You would be insane to think that you can osmote the ability to understand and use R code just by watching me do things on a screen. This facility takes practice, practice, hair pulling, and more practice. For those with little exposure to more advanced programming languages, today's workshop will be _very_ heavy with material. You shouldn't expect to absorb everything, but actively participating will help _a lot_.
 
 2. **Questions are openly encouraged!** As I mentioned, this will, despite my efforts to make things as straightforward as possible, inevitably be a somewhat dense workshop. So nobody should hesitate to stop me if they're lost. I am no fan of hearing myself speak, so if nobody in the audience is following me, that's a waste of everyone's time. 

***
***
***
# R Basics (8 AM - 9 AM)

Before we get to the fun stuff (statistical analysis), it's important that we gain some facility with doing basic things in R first -- adding numbers, creating objects, and tools for exploring/understanding new objects as we come across them, including understanding and overcoming common errors that can creep into our code.

First things first, let's follow the time-honored tradition of making R say "Hello World".

Make sure you're in the console (the cursor in front of the right angle bracket (`>`) should be blinking) and type (or copy-paste) the following:

```{r hello}
print("Hello World")
```


Easy-peasy. The console is a great place to do what I call sandboxing -- running small commands to test whether they run as expected and produce the right output in the right format, etc. But it would be very cumbersome to use the console to do everything. There's a distinct lack of permanency to anything we do in the console.

More common is to run code from an R script. You can create an R script in RStudio by clicking the plus-page icon (![New R script](http://imgur.com/eCEtq9e.png "plus-page icon")) and hitting "R Script" or by using the keyboard shortcut `Ctrl`+`Shift`+`N`. Try printing "Hello World" again by adding `print("Hello World")` to your new script and pressing `Ctrl`+`Enter` on this line. `Ctrl`+`Enter` is the shortcut for running the selected line, or for running a highlighted section of code.

Once we save our R script, we can easily share it with coauthors or the general public (or even ourselves, on a different computer), who can simply run the code again on their machine to reproduce your analysis. 

***
## Assignment

Consider the following:

```{r assign_scalar}
x = 3
```

When we execute the above line of code, we're creating the _variable_ `x` and associating with it the value `3`. This is like creating a `local` in Stata.

Variables (a.k.a. objects) are the most crucial building block for everything we want to do in R. When we create a variable, we create a shorthand for some value that we'll refer to lower in our code.

Assignment has to pass from right to left -- the _object_ on the right of `=` is assigned to the _name_ on the left of `=`.

The opposite is an error, since we haven't told R what `y` is yet:

```{r assign_error, error = TRUE}
3 = y
```

This error tells us that `3` is not a valid thing to which to assign; as a rule of thumb for beginners, all variable names must start with letters (though can contain other characters thereafter).

> > Side note: the following works just as well:
> >  `x <- 3`
> > this method of assignment is probably more common, but we'll stick with using `=` today since I think it's more intuitive. The differences between `=` and `<-` are all-but irrelevant for beginners, but for future reference, [this Q&A](http://stackoverflow.com/questions/1741820/) is worth a read: 

***
## Vectors

The easiest way to think of a vector is as a column (or a row) in Excel. A column in excel can contain many numbers, but instead of referring to each of them individually, we refer to the row. Typically, these numbers all have something in common (for example, a column Name in Excel should be filled with peoples' names).

The way to declare vectors in R is using `c`, which stands for _**c**_oncatenate:

```{r assign_vector}
x <- c(1, 2, 3, 4)
x
```

Now `x` contains four numbers. Note that since this type of sequence is so common, R has built in the colon (`:`) as an operator to create a variable like this more quickly/concisely:

```{r assign_sequence}
x <- 1:4
x
#Also works in reverse
x <- 4:1
x
```

***
## Types

Thus far, everything we've assigned to a variable has been a number. But this is _far_ from the only thing we can assign to a variable in R. Consider:

```{r assign_non_numeric}
x <- c("Philadelphia", "Pennsylvania")
y <- c(TRUE, FALSE)
z <- c(1L, 2L)
```

`x` contains a _string_ of letters _demarcated by `""` (or `''`) to distinguish them from variable names_. We refer to `x` as a `character` vector. 

`y` is a `logical` vector; it is often very convenient to keep binary variables (gender, treatment group, etc.) stored as `logical` variables, for reasons we'll see below.

`z` is an `integer` vector. This is distinguished from `c(1, 2)`, which gets stored as a `numeric` vector. The difference between the two probably won't affect you for quite some time, but it's often important for saving computer memory. `1`, as a `numeric`, takes up more space in your computer's memory than does `1L`. `L` signifies integer; don't worry about why (if you insist, it stands for _**L**_ong integer, which is too involved for this session).

### Lists

Consider this:

```{r assign_coerce}
x <- c(1, 2L, TRUE, "America")
```

All four components of `x` are of different type (namely, `numeric`, `integer`, `logical`, `character`). Recall above that we said vectors must have something in common, but as we declared it, this couldn't be further from the truth. In fact, R will force all of these components to have the same type -- namely, character:

```{r assign_coerce_print}
x
```

Note the quotation marks -- none of the components are any longer considered as `character` strings in `x`.

> > The specific heirarchy is `logical` < `integer` < `numeric` < `character`

However, mixing types is a fundamental feature of almost all data analysis, so it stands to reason that there is a straightforward way to do so. In R, this is done with the `list` type. We can replace the code above using `list`:

```{r assign_list}
x <- list(1, 2L, TRUE, "America")
x
```

Note how different the output looks, as compared to using `c`!! The quotation marks are gone except for the last component. You can ignore the mess of `[[` and `[` for now, but as an intimation, consider some more complicated `list`s:

```{r assign_lists}
x <- list(c(1, 2), c("a", "b"), c(TRUE, FALSE), c(5L, 6L))
x

y <- list(list(1, 2, 3), list(4:5), 6)
y
```

`x` is a `list` which has 4 components, each of which is a vector with 2 components. This gives the first hint at how R treats a dataset with many variables of different types -- at core, R stores a data set in a `list`!

`y` is a _nested_ `list` -- it's a `list` that has `list`s for some of its components. This is very useful for more advanced operations, but probably won't come up for quite some time, so don't worry if you haven't wrapped your head around this yet.

***
## Extraction/Indexing

Consider a simple `numeric` vector:

```{r extract_assign}
x <- 5:14
```

How do we get at the various numbers stored in certain positions in `x`? For example, how could we get the first number in `x`, `5`?

This process is called _extraction_, and, for vectors, is done with square brackets (`[]`), e.g.:

```{r extract_vector}
x[1] #first element of x

x[5] #fifth element of x
```

This also works on `list`s, but `list`s also have some other ways to get at their contents:

```{r extract_list}
y <- list(1:3, 4:6, 7:9)
y[1]
```

Note that the output still has `[[` in it. This means the result of `y[1]` is _still a list_.

More typically, we want to _remove_ the `list` structure and just get `1:3` instead of `list(1:3)`. To do this, we use `[[`:

```{r extract_list_item}
y[[1]]
```

### Named vectors and `list`s

It is also possible to name the elements of vectors and lists. This is convenient for making it easy to get certain elements without having to remember whether you stored it first, third, or whatever:

```{r extract_named}
x <- c("Iowa" = "Cruz", "Ohio" = "Kasich", "Pennsylvania" = "Trump")

y <- list(names = c("Kasich", "Cruz", "Trump"),
          ages = c(63, 45, 69),
          hates_clinton = c(TRUE, TRUE, TRUE))
```

For named vectors, we keep using `[]` to extract elements, but we can use the name instead of the index:

```{r extract_named_vector}
x["Iowa"]
```

For named `list`s, we can use `[]`, but, as with numbered indices, we'll get a `list` in return. If we want the actual object contained at that point in the list, we can still use `[[`, or we can also use `$`, which is another extraction operator:

```{r extract_named_list}
#now that y has names, we no longer see [[ -- instead, we see
#  the name of each element of the list
y["ages"]

y[["ages"]]

y$names
```

### Multiple extraction

As often as not, when we need to extract, we need _more than one_ element of the vector. 

To do this, we _pass a vector to `[]`_. It's must intuitive when we need elements in sequence, e.g.:

```{r extract_sequence}
# R conveniently keeps the letters of the
#   alphabet stored automatically in two
#   vectors, letters and LETTERS;
#   the former is lower-, the latter uppercase
x <- LETTERS
x

#Get the first 5 letters
x[1:5]
```

What if we need the first and 5th elements, but not the 3rd/4th/5th elements?

Remember that `1:5` is the same as `c(1, 2, 3, 4, 5)`. So we could have just used the latter:

```{r extract_sequence_long}
x[c(1, 2, 3, 4, 5)]
```

By extension, if we just want the first and fifth elements:

```{r extract_non_adjacent}
x[c(1, 5)]
```

_**NOTE**_: there's no* way to extract multiple elements using the other extraction operators, `[[` and `$`. It's an error to try:

```{r extract_errors, error = TRUE}
x <- list(a = 1:3, b = 4:6)
#multiple extraction by names works fine:
x[c("a", "b")]

#but not with [[ or $
x[[1:2]] #technically, R interprets this as a recursive index...

x[[c("a", "b")]] #again, a recursive index...

x$c("a", "b")
```

### Logical indexing

Another exceedingly common approach is to subset an object based on a condition satisfied by some of the elements.

Here, we must introduce the logical operators (also called _binary operators_, which is important for understanding associated error messages) in R.

These are `<`, `>`, `<=`, `>=`, `==`, and `!=`. These are all the same in Stata (note: `~=`, which works in Stata as an alternate to `!=`, _doesn't work in R_). First, let's explore them:

```{r logical_operators}
ages <- c(12, 14, 16, 18, 20, 22, 24, 30,
          38, 40, 55, 60, 63, 66, 68, 70)

#Who is voting age?
ages >= 18

#Who can't drink?
ages < 21

#Who is exactly 40?
ages == 40
```

Note that R automatically figures out whether _each element_ of `ages` satisfies the condition.

The way to extend this to extraction is simple:

```{r extract_logical}
#Only take people under age 18
ages[ages < 18]

#Only take AARPers
ages[ages >= 50]

#Exclude any 70 year old:
ages[ages != 70]
```

The other common logical operations are intersection, union and negation, aka **AND**, **OR** and **NOT**, which in R, as in Stata, are `&`, `|` and `!` (you'll also often see `&&` and `||` in other peoples' code; don't worry about the difference yet, but for those who know Matlab -- it's the same).

Quickly, let's get working-agers:

```{r extract_logical_pair}
ages[ages >= 18 & ages <= 65]
```

We can combine these to our heart's fancy and create any combination of logical requirements, e.g.:

```{r extract_logical_chain}
#get people who are over 18, but not exactly 34 or 70
ages[ages >= 18 & !(ages == 34 | ages == 70)]
```

### Negative indexing

Sometimes, we'd rather _exclude_ a small number of elements, rather than _include_ elements like we have been doing so far.

To do this, we precede the vector we want to extract with `-` (if it's `numeric`/`integer`/`character`) or `!` (if it's `logical`). 

Suppose we wanted to find out how many years have passed since our earliest observation, and to exclude the earliest observation. We might do something like:

```{r extract_negate}
years <- c(1970, 1973, 1978, 1980, 1990, 1995)
#the earliest year is 1970, which comes first; to exclude:
years[-1]
#to exclude and subtract 1970:
years[-1] - years[1]
```

***
## Base functions

R comes equipped with a vast (_vast_) library of built-in functions intended to make your life as a data analyst as easy as possible. As of this writing I count 1,203 functions included in base R, and 2,374 total functions that come ready to use as soon as you open up RStudio.

These are the real work horses of R, and many of them should be familiar to Excel and Stata users. Like in those programs, functions are distinguished by the use of parentheses `()` (in fact we've already used many functions to this point, most obviously the concatentation function `c`). We won't be able to get anyhwere near understanding all of the multitudinous functions R makes available to us today, but we can make a start.

### Basic Arithmetic/Stats

Finding the sum of a column in Excel is sort of a pain. You have to write `=SUM(` and then highlight all the proper cells. It's kind of a pain in Stata as well. You either have to `summarize var` the variable and run `di r(sum)` or create a new variable with `egen sum_var = sum(var)`. I find this and many other artihmetic operations much simpler to do in R.

```{r basic_arithmetic}
x <- 1:10

#find the sum
sum(x)

#find the mean
mean(x)

#find the variance and standard deviation
var(x)
sd(x)

#scalar arithmetic
3 * x
x - 2
x^2
x / 4

#exponentials
exp(1:3)
log(1:10)

#other arithmetic
abs(-5:5)

#rounding up/down
x <- c(.1, 1.1, 1.9, 2, 2.8)
floor(x)
ceiling(x)
```

### Function arguments

Most functions accept more than one argument. Consider rounding a number:

```{r round}
x <- c(1.12, 10.2, 1.56, 21.9, 2)
round(x)

#round to 1 digit past the decimal
round(x, 1)

#round to -1 digit past the decimal
#  (i.e., 1 digit befor the decimal)
round(x, -1)
```

There's no limit to the number of arguments a function can accept to accomplish a wide variety of tasks. With `round`, it's easy to handle this because there are only two arguments -- first, a vector of numbers, and second, a (single) number of digits to which to round the vector.

When the number of arguments balloons, however, it gets more and more difficult to keep track of which argument goes where.

Consider the `quantile` function, which takes 5 arguments -- `x`, a vector of numbers; `probs`, a vector of probabilities (quantiles); `na.rm`, which tells it whether to ignore missing data (more on that later); `names`, which tells R whether the result should be named (see example); and `type`, which tells R the algorithm to use for measuring the quantiles (there are 9 readily available).

It would be quite a pain to expect users to memorize the order in which `quantile` expects arguments, especially if we had to do so for every function we ever wanted to use (remember, there are _thousands_). To facilitate this, R allows us to _name_ our arguments.

```{r function_named_arguments}
x <- c(1, 1, 1, 2, 3, 4, 5, 6, 
       7, 8, 8, 8, 9, 10, 10, 10)

#by default, quantile calculates all 5 quartiles:
#  min, 25%-ile, median, 75%-ile, max
quantile(x)
median(x)

#if we just want the median
quantile(x, .5)
#or, we can name it to be explicit
quantile(x, probs = .5)

#if we want to exclude the names
quantile(x, probs = .5, names = FALSE)
```

In addition to making it easier for us as analysts to use the functions, naming arguments also makes it easier for _others_ to read our code. While it's fair to expect most users to know the basic functions and their arguments pretty well, the more advanced the function is that you're using, the more understandable your code gets when aided by named arguments.

### Infix operators and `match`

_Infix operators_ are things that are written from left to right like basic arithmetic, but which do things not covered by the five main arithmetic operators (`+`, `-`, `*`, `/`, `^`). These operators in R are always surrounded by two percent signs (`%`). The two math-y ones have to do with modular arithmetic:

```{r modular_arithmetic}
x <- 1:20
# integer division
x %/% 3
# modular division (remainder)
x %% 3
```

By far the most commonly used infix, though, has to be `%in%`. This is used to determine whether some objects (the left) can be found in another set (the right). Best with an example:

```{r %in%}
candidates <- 
  c("Bernie Sanders", "Hillary Clinton", "Lincoln Chafee", 
    "Jim Webb", "Laurence Lessig", "Donald Trump", "John Kasich",
    "Ted Cruz", "Marco Rubio", "Jeb Bush", "Ben Carson",
    "Carly Fiorina", "Lindsey Graham", "Chris Christie",
    "Rick Santorum", "Rand Paul", "Jim Gilmore", "Mike Huckabee",
    "George Pataki", "Bobby Jindal", "Scott Walker", "Rick Perry")

nominees <- c("Hillary Clinton", "Donald Trump")

candidates %in% nominees
```

A quick note that what `%in%` is actually doing is using the `match` function, which is also useful. `match` takes three arguments. The first and second are like the left- and right-hand side of `%in%`, respectively. `match` tries to find each element of the left in the right, and, if it's found, gives the position. The third argument, `nomatch` tells it what to do when the left element is _not_ found. Example:

```{r match}
color <- c("red", "green", "orange", "blue",
           "purple", "teal", "mahogany", "yellow",
           "orange", "white", "lavendar")

roygbiv <- c("red", "orange", "yellow", "green",
             "blue", "indigo", "violet")

#%in% tells you if each element of
#  color is in roygbiv at all
color %in% roygbiv

#match tells you WHERE in roygbiv 
#  each element of color was found;
#  we set no.match to say what
#  we expect when the color isn't found
#  (it must be an integer)
match(color, roygbiv, nomatch = -1)
```

### More useful functions

#### `length`

Length is used to find how many elements something has (in data, how many observations there are)

```{r length}
x <- 1:50
length(x)
```

#### `rep`

`rep` is used to _**rep**_eat an object a certain number of times. The `each` argument repeats each element a set number of times. `length.out` makes sure the output has a certain number of elements.

```{r rep}
rep(1:3, 4)

rep(1:3, each = 4)

rep(1:3, each = 4, length.out = 10)
```

#### `unique` / `duplicated`

`unique` eliminates all duplicates of a vector; `duplicated` returns a `logical` vector telling you which elements appeared earlier in the vector.

```{r unique/duplicated}
x <- c(1, 1, 1, 2, 2, 3)
unique(x)
duplicated(x)
### unique is the same as (but faster than) x[!duplicated(x)]
x[!duplicated(x)]

#unique is often used in conjunction with length
#  to find out the number of IDs in a vector, e.g.
length(unique(x))
```

#### `seq`

`seq` produces a _**seq**_uence. It has four main arguments: `to` (where to start), `from` (where to end), `by` (increment), and `length.out` (what should be the `length` of the result?). We must specify no more than 3 of these. Some examples:

```{r seq}
#same as 1:10
seq(10)

#same as 2:11
seq(2, 11)

#make a grid from 0 to 10 with 30 points;
#  R automatically figures out the increment
seq(0, 10, length.out = 30)

#get all the odd numbers from 1 to 50:
#  note that the upper endpoint won't
#  necessarily be included in the output
seq(1, 50, by = 2)
```

#### `sort`

`sort` will give an ordered version of its input. Default is increasing order; use the `decreasing` argument to reverse this.

```{r sort}
x <- c(1, 2, 4, -1, 8, 9, 20, 13, 0)
sort(x)
sort(x, decreasing = TRUE)
```

#### `paste` / `paste0`

`paste` and `paste0` are R's ways of concatenating strings, i.e., combining them together. `paste` has an argument `sep` which tells how to _**sep**_arate the components; `paste0` is a slightly faster version of `sep` that uses `sep = ""` (i.e., don't separate the output). The `collapse` argument, available to both, will reduce a vector to a single string, using `collapse` to separate. Examples:

```{r paste}
first <- c("Sam", "Charles", "Matthew", "Thom")
last <- c("Beam", "Mingus", "Embree", "Yorke")

#default sep is a space, sep = " "
paste(first, last)
paste(last, first, sep = ", ")
paste(last, first, collapse = ", ")
paste0(first, last, collapse = ", ")
```

***
## Random Numbers

As statistical analysts, randomness is our lifeblood. As a language designed for statistical analysis, then, it stands to reason that R comes well-equipped to handle many common statistical operations. This includes producing random numbers a number of common distributions, random permutations, random subsets, etc.

### Uniform and normal random numbers

The most common kind of random numbers that people want are uniform draws and normal draws. 

```{r unif/norm}
#generate 10 U[0, 1] draws
runif(10)
#generate 10 U[3, 5] draws
runif(10, min = 3, max = 5)

#generate 10 N(0, 1) draws
rnorm(10)
#generate 10 N(3, 5) draws
rnorm(10, mean = 3, sd = 5)
```

These examples highlight the common format of random number generators in R. To get random numbers from a distribution, there is probably a function named like `r`**`dist`**, where **`dist`** is an abbreviation for the distribution (here, **unif**orm and **norm**al). The first argument is the number of draws; the rest of the arguments are parameters.

Here is a complete table of all of the common distributions built in to R, and the function used to invoke their random number generator (RNG):

                   Distribution RNG          Other Parameters          Wikipedia
 ------------------------------ ------------ ------------------------- ----------
                           Beta `rbeta`      `shape1`, `shape2`, `ncp` https://en.wikipedia.org/wiki/Beta_distribution
                       Binomial `rbinom`     `size`, `prob`            https://en.wikipedia.org/wiki/Binomial_distribution
                         Cauchy `rcauchy`    `location`, `scale`       https://en.wikipedia.org/wiki/Cauchy_distribution
                    Chi-Squared `rchisq`     `df`, `ncp`               https://en.wikipedia.org/wiki/Chi-squared_distribution
                    Exponential `rexp`       `rate`                    https://en.wikipedia.org/wiki/Exponential_distribution
                              F `rf`         `df1`, `df2`, `ncp`       https://en.wikipedia.org/wiki/F-distribution
                          Gamma `rgamma`     `shape`, `rate`, `scale`  https://en.wikipedia.org/wiki/Gamma_distribution
                      Geometric `rgeom`      `prob`                    https://en.wikipedia.org/wiki/Geometric_distribution
                 Hypergeometric `rhyper`     `m`, `n`, `k`             https://en.wikipedia.org/wiki/Hypergeometric_distribution
                     Log-Normal `rlnorm`     `meanlog`, `sdlog`        https://en.wikipedia.org/wiki/Log-normal_distribution
                       Logistic `rlogis`     `location`, `scale`       https://en.wikipedia.org/wiki/Logistic_distribution
                    Multinomial `rmultinom`  `size`, `prob`            https://en.wikipedia.org/wiki/Multinomial_distribution
              Negative Binomial `rnbinom`    `size`, `prob`, `mu`      https://en.wikipedia.org/wiki/Negative_binomial_distribution
                        Poisson `rpois`      `lambda`                  https://en.wikipedia.org/wiki/Poisson_distribution
 Wilcoxon Sign Ranked Statistic `rsignrank`* `n`                       https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test
                      Student t `rt`         `df`, `ncp`               https://en.wikipedia.org/wiki/Student%27s_t-distribution
                        Weibull `rweibull`   `shape`, `scale`          https://en.wikipedia.org/wiki/Weibull_distribution
 Wilcoxon Sign Ranked Statistic `rwilcox`*   `m`, `n`                  https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test
                        Wishart `rWishart`   `df`, `Sigma`             https://en.wikipedia.org/wiki/Wishart_distribution

Table: List of native distributions from built-in `stats` package

In addition to RNGs, R typically has three other functions associated with a given distribution: a **d**ensity function with prefix `d`, e.g. `dnorm`, giving the PDF; a **p**robability function with prefix `p`, e.g. `pnorm`, giving the CDF; and a **q**uantile function with prefix `q`, e.g. `qnorm`, giving quantiles. 

```{r dist}
#this is mainly used for plotting, see below
dnorm(seq(-3, 3, length.out = 30))

#great for calculating p values
pnorm(1.96)

#great for getting critical values
qnorm(c(.005, .025, .05))
```

### `sample`

As often as we need random draws from uniform or normal distributions, we need to take random subsets of vectors, or to get random integers. The main function for tasks like this is `sample`, which takes 4 arguments: `x` (a vector from which to sample, or an integer representing the max of numbers from which to sample), `size` (the number of elements to sample, which defaults to `length(x)`), `replace` (whether draws are taken with replacement), and `prob` (a vector of probabilities, for weighted sampling -- default is uniform).

As always, it's easiest to see with some examples:

```{r sample}
#A permutation of 1:5
sample(5)
#A size-3 subset of 1:5
sample(5, 3)
#A size-5 subset of 1:5, with replacement
sample(5, 5, replace = TRUE)

#A weighted sample of 1:5, heavily weighting 1
sample(5, 5, replace = TRUE, prob = c(.99, .0025, .0025, .0025, .0025))
```

We can use the basic tools here to run basic randomization exercises, like rolling dice, flipping coins, or drawing cards from a deck:

```{r dice/coins/cards}
#Flip 10 coins, get the percentage heads
flips <- sample(c("H", "T"), 10, replace = TRUE)
mean(flips == "H")

#Roll a pair of dice and add them
sum(sample(6, 2, replace = TRUE))

#create a deck of labeled cards:
#  (I copy-pasted the text for the suits from
#   Wikipedia, but we could have used S/H/D/C:
#   https://en.wikipedia.org/wiki/Playing_cards_in_Unicode)
deck <- paste0(rep(c(2:10, "J", "Q", "K", "A"), 4),      #card values
               rep(c("♠", "♥", "♦", "♣"), each = 13)) #suits
deck

#Now draw a poker hand
sample(deck, 5)
```

### `replicate`

Full scale Monte Carlo/bootstrapping requires replicating a simulation exercise over and over. Again, R is ready and has the `replicate` function for us. Let's simulate a few poker hands to find their frequency and compare with the theoretical frequency:

```{r poker}
#It'll be easier to deal with numbers than
#  with the fancy strings we used above
deck_nos <- 1:52
#Simulating a flush
simulations <- 
  replicate(10000, #number of repetitions/simulations
            { #use curly braces to run a simulation that takes more than one line
              hand <- sample(deck_nos, 5) #draw a five-card hand
              suits <- hand %% 4 # force card number into one of 4 categories
              length(unique(suits)) == 1 #returns TRUE if all suits are equal, FALSE else
            }) #close braces and parentheses
#How often does a flush happen?
#  True frequency is 0.1965%
mean(simulations)

#What about a pair (just two cards match)?
#  true frequency: 42%
simulations <- 
  replicate(10000, {
    hand <- sample(deck_nos, 5)
    faces <- hand %% 13 # force into one of 13 categories
    sum(duplicated(faces)) == 1 #one pair if there's exactly _one_ match
  })
mean(simulations)
```

### `set.seed`

Just a quick note that any time we run a simulation, it's a good idea (for _replicability_) to _set and save the random seed_! Random numbers from computers may look random, but in fact they're completely deterministic -- if we know the value of the random seed! This is a disadvantage for information security (which is only sometimes important to us as data analysts), but an advantage for academic research, where replicability is paramount.

A simple example:
```{r seed}
set.seed(100)
runif(1)

#if we run again, we'll get a different number
runif(1)
#but if we re-set the seed, we'll get the same
set.seed(100)
runif(1)
```

***
## Vectorization / `*apply`

The last set of major workhorse functions in `R` are the `*apply` functions -- `sapply` and `lapply`. `apply` is also important, but I want to avoid touching on matrices today, if I can. The oft-ignored cousins are `rapply` (**r**ecursive), `tapply` (**t**agged), `mapply` (**m**ultivariate), `vapply` (**v**erified), and `eapply` (**e**nvironment). 

You should think of `lapply` as **l**ist apply and `sapply` as **s**implified apply, because the former returns a `list`, and the latter returns a more simplified object (vector/matrix/array).

Both of these functions are, by and large, what you should be using in R instead of a `for` loop. A `for` loop often consists of going through every element of a `list` and doing something to its contents. `for` loops exist in R, as they probably do in every langauge, but are typically much slower than what is often called a vectorized approach. We'll get into that more later, but for now I'll just leave an example of `lapply` and `sapply` in action:

```{r apply}
#pick three triplets of numbers at random
l <- list(sample(100, 3), sample(100, 3), sample(100, 3))
l

#now find the max within each group
lapply(l, max)

#note that the output is a list. It's typically
#  more convenient to have the output as a vector:
sapply(l, max)
```

***
## Packages

One of the things that makes R truly exceptional is its vast library of user-contributed packages.

R comes pre-loaded with a boat-load of the most common functions / methods of analysis. But in no way is this congenital library complete.

Complementing this core of the most common operations are external _packages_, which are basically sets of functions designed to accomplish specific tasks. The entire afternoon of this workshop is devoted to gaining facility in just a few of these.

Best of all, unlike some super-expensive programming languages, all of the thousands of packages available to R users (most importantly through CRAN, the **C**omprehensive **R** **A**rchive **N**etwork) are _completely free of charge_. 

The two most important things to know about packages for now (we'll start using my favorite, `data.table`, shortly) is where to find them, how to install them, and how to load them.

### Where to find packages

Long story short: Google. Got a particular statistical technique in mind? The best R package for this is almost always the top Google result if asked correctly.

How about heirarchical linear modeling (HLM)? A quick Google for "HLM R" or "heirarchical linear modeling R" both turn up some articles/tutorials/CRAN pages referencing `lmer`. 

### How to install packages

Just use `install.packages`!

```{r install.packages, eval = FALSE}
#we won't be able to run this, because it requires
#  administrative priviliges, but you can do
#  this easily on your own computer
install.packages("lmer")
```

### How to load packages

Just add it to your library!

```{r library, eval = FALSE}
#this won't run if it's not installed
library(lmer)
```

_Et voila_! You'll now be able to run HLM in R. You can also Google "tutorial lmer" (or in general "tutorial [package name]") and you're very likely to find a trove of sites trying to help you learn the package. Most popular packages also come with worked examples available through the example function, e.g., `example(package = "lmer")`.

***
## Toolkit: `ls`/`rm`/`?`/`class`/`dput`/`str`

Just a few more things that aren't related to statistical analysis _per se_, but which will often facilitate your coding experience.

First, `ls` and `rm`, short-hand for **l**i**s**t objects and **r**e**m**ove objects. These can be useful for understanding what names you've assigned to objects, and for occasionally cleaning up the clutter of variables you'll no longer use (for the meticulously clean, but also because leaving a bunch of unused objects lying around is a great way to create irritating errors / problems with your code).

Let's see all the junk we've created thus far in the workshop:

```{r lsrm}
#ls is a function, so we have to use () to call it
ls()

#one of the optional arguments to ls is to 
#  also list some "hidden" objects:
ls(all = TRUE)

#what a mess! let's get rid of some stuff
rm(ages, candidates, color)

#ugh, this is getting boring. What about
#  a scorched earth technique?
rm(list = ls(all = TRUE))

#after the apocalypse, nothing remains:
ls(all = TRUE)
```

### Troubleshooting

Finally, I'll leave you with some tools that are often the first place to look when trying to troubleshoot code that isn't working correctly.

#### `?`

`?` is the help operator in R. If you'd like to know _anything_ about any function in R, just type `?` before its name and hit enter. Let's start with the help page for `replicate` by entering `?replicate`. All help files are structured similarly, with the following common sections (I've highlighted in **bold** the most useful for troubleshooting):

 1. Description: an overview of the function(s) described on the page. `?replicate`, for example, redirects us to the help page for `lapply`, since in addition to `replicate` this page covers `lapply`, `sapply`, `vapply`, and `simplify2array` (don't worry about the last two, they're a bit more advanced and won't come up today).
 2. **Usage**: a generic snippet of code which shows the name and default value of every argument of every function on the page. This is very useful for understanding the ordering and naming of all the arguments to a function. `replicate`, for example, has 3 arguments, only 2 of which we used above: `n` is the number of repetitions, which has no default; `expr` is the expression to repeat (surrounded in curly braces `{}` above), which has no default; and `simplify`, which gives us control over how/whether the results are converted from a `list`, which has default `"array"`, leading to the output we saw above. 
 3. **Arguments**: gives a brief overview of what each function expects to receive for each argument (the type, whether it can be a vector or has to be a scalar, etc.). You shouldn't expect to fully understand everything that's being told to you here for a while, since it's pretty specific, but it can still help.
 4. Details: Some nitty-gritty about how the functions work, some mistakes to avoid, some of the more intricate details of how exactly the function goes about its task. Tends to be very dense and jargon-heavy.
 5. Value: Tells you details about the _type_ of object that you should expect to be returned as a result of running each function (e.g., we noted that `lapply` _always_ returns a `list`; this is noted in the Value section of `?replicate` in the first sentence).
 6. Note: Some more technical details about the function and its edge cases.
 7. References: Especially useful for packages -- this usually tells you where to go to find some more reading about the algorithms implemented.
 8. See Also: Gives some related functions which might also help accomplish similar tasks.
 9. **Examples**: A great place to look for some simple reproducible examples of how the functions work, with code that can be copy-pasted and run by you, the user.
 
The help files are an absolute _must_ go-to reference -- it's always the first place you should check when you're stuck.

#### `class`

`class` simply tells you the class/type of an object in memory. You'd be surprised how often the root of an issue is simply that _you_ think a certain variable is type X (say, `numeric`), but actually R is keeping track of it as if it's type Y (frighteningly often, `factor` -- more on that later).

#### `dput`

`dput` is like a microscope for R objects. It deconstructs any variable in R to its atoms -- its absolute fundamental components -- and prints out what's hidden under the hood. This is especially useful because all of the most complicated objects in R tend to have an associated `print` method which renders them in a digestible form. This is great for taking a glance at a complicated object, but not useful for understanding what's going wrong with that object.

Take, for example:

```{r dput}
#we'll get more into how R understands dates/times
#  later in the day; the key takeaway here is 
#  how R prints the object vs. how it's actually stored.
t <- as.POSIXlt("2015-05-12")
t
#when we just enter the object at the console, its
#  print method is invoked, i.e.:
print(t)

#this is a bit misleading. From what we see, it would appear
#  that t is just a character string. However:
t == "2015-05-15 EDT"

#so, what is t? use dput
dput(t)
#actually, it's a rather complicated list with components
#  describing every which thing about the date/time we entered
```

#### `str`

Often the output of `dput` is far too verbose to be of real use. `str` is a similar function which gives us a more detailed look at the components of a complicated object, but with the advantage that it doesn't give us too many details; it's more like a table of contents for R objects.

```{r str}
#don't worry about what lm is yet, we'll get there soon
y <- rnorm(1000)
x <- rnorm(1000)
r <- lm(y ~ x)
str(r)
```

Whew, that was a lot! Congratulations!

Now, on to the more fun and useful stuff!

***
***
***
# Data Basics (9 AM - 11 AM)

* Missing Data
* `table`

## Reading .csv Files

### `fread`/`data.table`

## Regressions

### OLS (`lm`) / `predict`/`coeftest`/`summary`

### Probit/Logit (`glm`)

## Reshaping

## Merging

## String Data / regex

## Non-.csv Data

### SAS: `read_sas`

### Excel: `readxl` / `xlsx`

### Fixed-width `read_fwf`

# Plotting / Tables (11 AM - 12 PM)

## Descriptive Tables

## Regression Tables: `texreg`/`xtable`

## `base` Plots

`axes`/`matplot`

## `ggplot`

# Web Scraping: `rvest` (1:30 PM - 2:30 PM)

`xpath`

# Geospatial Tools (2:30 PM - 3:30 PM)

`S4` methods/`@`slots, `CRS`

# Automatic Presentations/Papers: `knitr` (3:30 PM - 4:30 PM)

# Dynamic/Interactive Output: `shiny` (4:30 PM - 5:30 PM)

# Appendix

`vapply`

`CJ`

`setkey`

## Data Cleaning

## Source Code

## Package development

## Advanced types