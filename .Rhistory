round(x, 1)
#round to -1 digit past the decimal
#  (i.e., 1 digit befor the decimal)
round(x, -1)
# Chunk 30: function_named_arguments
x <- c(1, 1, 1, 2, 3, 4, 5, 6,
7, 8, 8, 8, 9, 10, 10, 10)
#by default, quantile calculates all 5 quartiles:
#  min, 25%-ile, median, 75%-ile, max
quantile(x)
median(x)
#if we just want the median
quantile(x, .5)
#or, we can name it to be explicit
quantile(x, probs = .5)
#if we want to exclude the names
quantile(x, probs = .5, names = FALSE)
# Chunk 31: modular_arithmetic
x <- 1:20
# integer division
x %/% 3
# modular division (remainder)
x %% 3
# Chunk 32: %in%
candidates <-
c("Bernie Sanders", "Hillary Clinton", "Lincoln Chafee",
"Jim Webb", "Laurence Lessig", "Donald Trump", "John Kasich",
"Ted Cruz", "Marco Rubio", "Jeb Bush", "Ben Carson",
"Carly Fiorina", "Lindsey Graham", "Chris Christie",
"Rick Santorum", "Rand Paul", "Jim Gilmore", "Mike Huckabee",
"George Pataki", "Bobby Jindal", "Scott Walker", "Rick Perry")
nominees <- c("Hillary Clinton", "Donald Trump")
candidates %in% nominees
# Chunk 33: match
color <- c("red", "green", "orange", "blue",
"purple", "teal", "mahogany", "yellow",
"orange", "white", "lavendar")
roygbiv <- c("red", "orange", "yellow", "green",
"blue", "indigo", "violet")
#%in% tells you if each element of
#  color is in roygbiv at all
color %in% roygbiv
#match tells you WHERE in roygbiv
#  each element of color was found;
#  we set no.match to say what
#  we expect when the color isn't found
#  (it must be an integer)
match(color, roygbiv, nomatch = -1)
# Chunk 34: length
x <- 1:50
length(x)
# Chunk 35: rep
rep(1:3, 4)
rep(1:3, each = 4)
rep(1:3, each = 4, length.out = 10)
# Chunk 36: unique/duplicated
x <- c(1, 1, 1, 2, 2, 3)
unique(x)
duplicated(x)
### unique is the same as (but faster than) x[!duplicated(x)]
x[!duplicated(x)]
#unique is often used in conjunction with length
#  to find out the number of IDs in a vector, e.g.
length(unique(x))
# Chunk 37: seq
#same as 1:10
seq(10)
#same as 2:11
seq(2, 11)
#make a grid from 0 to 10 with 30 points;
#  R automatically figures out the increment
seq(0, 10, length.out = 30)
#get all the odd numbers from 1 to 50:
#  note that the upper endpoint won't
#  necessarily be included in the output
seq(1, 50, by = 2)
# Chunk 38: sort
x <- c(1, 2, 4, -1, 8, 9, 20, 13, 0)
sort(x)
sort(x, decreasing = TRUE)
# Chunk 39: paste
first <- c("Sam", "Charles", "Matthew", "Thom")
last <- c("Beam", "Mingus", "Embree", "Yorke")
#default sep is a space, sep = " "
paste(first, last)
paste(last, first, sep = ", ")
paste(last, first, collapse = ", ")
paste0(first, last, collapse = ", ")
# Chunk 40: unif/norm
#generate 10 U[0, 1] draws
runif(10)
#generate 10 U[3, 5] draws
runif(10, min = 3, max = 5)
#generate 10 N(0, 1) draws
rnorm(10)
#generate 10 N(3, 5) draws
rnorm(10, mean = 3, sd = 5)
# Chunk 41: dist
#this is mainly used for plotting, see below
dnorm(seq(-3, 3, length.out = 30))
#great for calculating p values
pnorm(1.96)
#great for getting critical values
qnorm(c(.005, .025, .05))
# Chunk 42: sample
#A permutation of 1:5
sample(5)
#A size-3 subset of 1:5
sample(5, 3)
#A size-5 subset of 1:5, with replacement
sample(5, 5, replace = TRUE)
#A weighted sample of 1:5, heavily weighting 1
sample(5, 5, replace = TRUE, prob = c(.99, .0025, .0025, .0025, .0025))
# Chunk 43: dice/coins/cards
#Flip 10 coins, get the percentage heads
flips <- sample(c("H", "T"), 10, replace = TRUE)
mean(flips == "H")
#Roll a pair of dice and add them
sum(sample(6, 2, replace = TRUE))
#create a deck of labeled cards:
#  (I copy-pasted the text for the suits from
#   Wikipedia, but we could have used S/H/D/C:
#   https://en.wikipedia.org/wiki/Playing_cards_in_Unicode)
deck <- paste0(rep(c(2:10, "J", "Q", "K", "A"), 4),      #card values
rep(c("♠", "♥", "♦", "♣"), each = 13)) #suits
deck
#Now draw a poker hand
sample(deck, 5)
# Chunk 44: poker
#It'll be easier to deal with numbers than
#  with the fancy strings we used above
deck_nos <- 1:52
#Simulating a flush
simulations <-
replicate(10000, #number of repetitions/simulations
{ #use curly braces to run a simulation that takes more than one line
hand <- sample(deck_nos, 5) #draw a five-card hand
suits <- hand %% 4 # force card number into one of 4 categories
length(unique(suits)) == 1 #returns TRUE if all suits are equal, FALSE else
}) #close braces and parentheses
#How often does a flush happen?
#  True frequency is 0.1965%
mean(simulations)
#What about a pair (just two cards match)?
#  true frequency: 42%
simulations <-
replicate(10000, {
hand <- sample(deck_nos, 5)
faces <- hand %% 13 # force into one of 13 categories
sum(duplicated(faces)) == 1 #one pair if there's exactly _one_ match
})
mean(simulations)
# Chunk 45: seed
set.seed(100)
runif(1)
#if we run again, we'll get a different number
runif(1)
#but if we re-set the seed, we'll get the same
set.seed(100)
runif(1)
# Chunk 46: apply
#pick three triplets of numbers at random
l <- list(sample(100, 3), sample(100, 3), sample(100, 3))
l
#now find the max within each group
lapply(l, max)
#note that the output is a list. It's typically
#  more convenient to have the output as a vector:
sapply(l, max)
# Chunk 49: lsrm
#ls is a function, so we have to use () to call it
ls()
#one of the optional arguments to ls is to
#  also list some "hidden" objects:
ls(all = TRUE)
#what a mess! let's get rid of some stuff
rm(ages, candidates, color)
#ugh, this is getting boring. What about
#  a scorched earth technique?
rm(list = ls(all = TRUE))
#after the apocalypse, nothing remains:
ls(all = TRUE)
# Chunk 50: dput
#we'll get more into how R understands dates/times
#  later in the day; the key takeaway here is
#  how R prints the object vs. how it's actually stored.
t <- as.POSIXlt("2015-05-12")
t
#when we just enter the object at the console, its
#  print method is invoked, i.e.:
print(t)
#this is a bit misleading. From what we see, it would appear
#  that t is just a character string. However:
t == "2015-05-15 EDT"
#so, what is t? use dput
dput(t)
#actually, it's a rather complicated list with components
#  describing every which thing about the date/time we entered
# Chunk 51: str
#don't worry about what lm is yet, we'll get there soon
y <- rnorm(1000)
x <- rnorm(1000)
r <- lm(y ~ x)
str(r)
# Chunk 52: head
#Just to flex some of R's muscles, we'll find
#  the data file from within R. As often as not,
#  we'll just navigate to the file ourselves and
#  just copy-paste the file path.
#  We're looking for the folder with the data
#  so we use include.dirs to include directories
list.files(include.dirs = TRUE)
#I've kept things in the data folder here. We
#  can tell it's a folder as it has no extensions.
#  We can find the files in that folder using a
#  relative path (./ means starting from the
#  current folder, enter the folder after /).
#  We use the full.names of the file for the next step.
list.files("./data", full.names = TRUE)
#Now we see the data files. The one we're after
#  currently is "School Profiles Teacher Attendance 2013-2014.TXT"
#  To get it previewed, we send the command head to the system
#  and follow it with the quoted file name (since the
#  file name has spaces, which is a pain)
command = paste0('head ', '"./data/School Profiles Teacher Attendance 2013-2014.TXT"')
# Chunk 54: system_eval
#See: http://stackoverflow.com/questions/27388964
#  seems I have to jump through hoops to get system to work with knitr
cat(system(command, intern = TRUE), sep = "\n")
# Chunk 56: fread
#load the data.table package
library(data.table)
attendance <-
fread("./data/School Profiles Teacher Attendance 2013-2014.TXT")
# Chunk 57: print.data.table
attendance
#we can also explicitly invoke print,
#  which has a few more bells and whistles to
#  facilitate understanding what our data.table
#  looks like.
print(attendance, class = TRUE)
# Chunk 58: explore_data.table
class(attendance)
str(attendance)
is.list(attendance)
# Chunk 59: extract_column
attendance$SCH_TEACHER_ATTEND
# Chunk 60: attend_summary
#Summarize the variable to get a quick understanding
#we're looking at ALL rows, so we leave the first argument BLANK
#we're trying to summarize SCH_TEACHER_ATTEND, so we
#  use the summary function in the second argument
attendance[ , summary(SCH_TEACHER_ATTEND)]
# Chunk 61: attend_high_low
#We are focusing on certain rows, so we
#  say the condition defining those
#  rows in the first argument
attendance[SCH_TEACHER_ATTEND < 90]
#And schools with particularly high attendance
attendance[SCH_TEACHER_ATTEND > 97]
# Chunk 62: readme
writeLines(readLines("./data/README_SDP_Employee.txt"))
# Chunk 63: read_salaries
salaries <- fread("./data/employee_information.csv")
print(salaries, class = TRUE)
#it's a pain to have to lay on the SHIFT key all the
#  time, so let's rename the columns so that
#  are in lower case. We need three functions:
#  tolower, which takes all upper-case letters in a
#  string and replaces them with their lower-case
#  counterpart; names, which returns the names of
#  any object (vector, list, data.table, etc.);
#  and setnames, which has three arguments:
#  1) a data.table, 2) the columns to rename, and
#  3) their replacements. If we only use two arguments,
#  R assumes we want to replace _all_ column names, and
#  that the second argument is the replacement values.
setnames(salaries, tolower(names(salaries)))
#checking the result:
salaries
# Chunk 64: explore_salaries
#table is a great function for describing discrete variables.
#  it gives the count of observations in each cell, and can also
#  be used to create what Stata calls two-way tables.
salaries[ , table(pay_rate_type)]
salaries[ , table(organization_level)]
#a cross-tabulation of these two; the first argument will
#  appear in the rows, the second in the columns
salaries[ , table(pay_rate_type, organization_level)]
salaries[ , table(organization_level, gender)]
# Chunk 65: salaried
salaried <- salaries[pay_rate_type == "SALARIED"]
# Chunk 66: find_teachers
#Let's take it step-by-step
# 1: Find the count of employees in each category
salaried[ , .N, by = title_description]
# 2: reorder these to find the most common
salaried[ , .N, by = title_description][order(N)]
# 3: put it in decreasing order
salaried[ , .N, by = title_description][order(-N)]
# 4: Only look at the top 20 most frequent positions
# (idea -- once it's resorted, these are simply
#  the first twenty rows of the sorted table)
salaried[ , .N, by = title_description][order(-N)][1:20]
# Chunk 67: get_teachers
teachers <- salaried[title_description == "TEACHER,FULL TIME"]
teachers
# Chunk 68: gender_gap
#simple to code!
teachers[ , mean(pay_rate), by = gender]
#mean automatically got called V1. If we want
#  a more friendly output, we have to change a little:
teachers[ , .(avg_wage = mean(pay_rate)), by = gender]
# Chunk 69: organization_gap
teachers[ , .(avg_wage = mean(pay_rate)), by = organization_level]
# Chunk 70: rich_school
teachers[ , .(avg_wage = mean(pay_rate)),
by = home_organization_description
][order(-avg_wage)]
# Chunk 71: rich_school_2
#remember our handy friend .N!!
teachers[ , .(.N, avg_wage = mean(pay_rate)),
by = home_organization_description
][order(-avg_wage)]
# Chunk 72: rich_school_3
#No longer keep .N as an output -- this is just for focus,
#  since we already know all the schools have at least
#  ten teachers
teachers[ , if (.N >= 10) .(avg_wage = mean(pay_rate)),
by = home_organization_description
][order(-avg_wage)]
# Chunk 74: attendance_redux
attendance
# Chunk 75: compare_ids
#We know from attendance there are 212 schools.
#  How many unique schools are represented in the teacher data?
teachers[ , uniqueN(home_organization)]
#How many of the ULCS_NO values are also found in home_organization
#  intersect find the middle of the venn diagram for the
#  first and second arguments
length(intersect(attendance$ULCS_NO, teachers[ , unique(home_organization)]))
# Chunk 76: defining
#add attendance as a proportion
attendance[ , attendance_proportion := SCH_TEACHER_ATTEND / 100]
#add relative attendance
attendance[ , attendance_relative := SCH_TEACHER_ATTEND / SDP_TEACHER_ATTEND]
#a quirk of data.table is that after using
#  :=, we sometimes have to force printing,
#  which we can do by appending [] to the end
attendance[]
#add logical version of gender
teachers[ , male := gender == "M"]
#now, subset to show only male teachers
teachers[(male)]
# Chunk 77: merge_school_name
#this will take the FIRST row associated
#  with each school. This is important in
#  general, but not here since we only
#  care about the school-level data for now,
#  which is the same in all rows.
schools <- unique(teachers, by = "home_organization")
schools
#now merge, using := to add the school name column
attendance[schools, school_name :=
home_organization_description,
on = c(ULCS_NO = "home_organization")]
attendance
# Chunk 78: merge_alternatives
attendance[ , school_name := NULL][]
#alternative 1: skip defining schools
#  extra tidbit: sometimes, both the
#  main table (x) and the merging table
#  (in the first argument, i -- we called
#   it Y above) have columns with the same
#  name. To overcome the ambiguity this
#  engenders, we can prepend i. to the
#  column names in teachers to tell R
#  that we're referring _explicitly_
#  to that column in teachers. Similarly,
#  we can prepend x. to tell R that we're
#  referring to the column in attendance
attendance[unique(teachers, by = "home_organization"),
school_name := i.home_organization_description,
on = c(ULCS_NO = "home_organization")][]
#reset again
attendance[ , school_name := NULL]
#alternative 2: use unique within the merge
#  by = .EACHI is a syntax unique to merging.
#  Using this tells R to do the thing in j
#  within each group that's matched.
#  So, here, each ULCS_NO gets matched to many
#  home_organization rows in teachers.
#  within this group, we use unique to
#  get the school's name, since unique turns the
#  vector of school names (one per teacher in
#  each school that's matched) into a single value.
attendance[teachers,
school_name := unique(home_organization_description),
on = c(ULCS_NO = "home_organization"), by = .EACHI][]
#reset again
attendance[ , school_name := NULL]
#alternative 3: like 2, except use [] instead of unique.
#  This alternative works, and is faster, but is less robust
#  to finding mistakes in your data. Thankfully, this data is
#  pretty clean, but we often find messy data in the wild --
#  maybe there was a typo in the organization code or school name,
#  and instead of each home_organization being matched to
#  exactly one home_organization_description, we might find
#  it matched to several (e.g., "PS 131" and "PS #131").
#  If we use the unique approach from alternative 2,
#  we'll get an error, which tells us we need to examine our data
#  more closely. This approach will definitely not generate an error.
attendance[teachers,
school_name := home_organization_description[1],
on = c(ULCS_NO = "home_organization"), by = .EACHI][]
# Chunk 79: show_na
#is.na returns a logical vector saying
#  whether each element of school_name
#  is missing (NA) or not
attendance[is.na(school_name)]
#NOTE: TESTING NA WITH EQUALITY DOESN'T WORK
attendance[school_name == NA]
# Chunk 80: show_masterman
#remember, salaries is the full set
#  of ALL employees of SDP -- we
#  didn't remove any observations from here
#(using the nrows argument for print to condense output)
print(salaries[home_organization == "2140"], nrows = 10)
#since they're not full-time teachers, what are they?
salaries[home_organization == "2140",
table(title_description)]
# Chunk 81: other_demo_teachers
salaries[title_description == "TEACHER,DEMONSTRATION",
.N, by = home_organization_description]
# Chunk 82: re_merge
attendance[salaries,
school_name := unique(home_organization_description),
on = c(ULCS_NO = "home_organization"), by = .EACHI]
attendance[is.na(school_name)] #fixed!
# Chunk 83: call_out_attendance
attendance[SCH_TEACHER_ATTEND < 90 |
SCH_TEACHER_ATTEND > 97
][order(-SCH_TEACHER_ATTEND),
.(ULCS_NO, school_name, SCH_TEACHER_ATTEND)]
# Chunk 85: readxl
library(readxl)
#As we saw, this file has many sheets. the read_excel function
#  has an argument sheet which we use to specify the sheet we want
#Also, as we saw, there's a bunch of extraneous rows at the top of the file.
#  We use the skip argument to ignore them. But in so doing, we necessarily
#  lose some information (namely, which columns correspond to Female and
#  which correspond to Male).
#To overcome this, we're going to supply
#  the column names ourselves. This is also favorable since the column
#  headers in the raw data file are plagued by spaces -- which makes
#  them quite hard to deal with once they're brought into R.
school_gender <-
read_excel("./data/2015-2016 Enr Dem (Suppressed).xls",
sheet = "Gender", skip = 6,
#enter a blank for the first column, which
#  will be dropped anyway
col_names = c("", "school_id", "school_name", "grade",
"total_enrolled", "count_female",
"pct_female", "count_male", "pct_male"))
# Chunk 86: setDT
class(school_gender)
#(usually, I just do this wrap this
# around read_excel to do it all at once)
setDT(school_gender)
class(school_gender)
# Chunk 87: gender_preview
print(school_gender, class = TRUE)
# Chunk 88: gender_cleanup
#subsetting
school_gender <- school_gender[grade == "ALL GRADES"]
#forcing numeric -- note the warning telling us
#  there is some data loss because R doesn't know
#  how to convert "s" to a number, so it forces it to be NA
school_gender[ , count_female := as.numeric(count_female)]
#repeat for the other columns
school_gender[ , pct_female := as.numeric(pct_female)]
school_gender[ , count_male := as.numeric(count_male)]
school_gender[ , pct_male := as.numeric(pct_male)]
# Chunk 89: .SD
school_gender[ , .SD]
# Chunk 90: .SD_subset
#the same as school_gender[1:10]
school_gender[ , .SD[1:10] ]
#get the entire first row associated with each school_id
school_gender[ , .SD[1], by = school_id]
# Chunk 91: .SDcols
school_gender[ , .SD, .SDcols = c("school_id", "grade", "total_enrolled")]
#Troublesome. We don't want to convert
#  most of the columns, and we go too far here
school_gender[ , lapply(.SD, as.numeric)]
#Use .SDcols to control which columns we affect
school_gender[ , lapply(.SD, as.numeric),
.SDcols = c("count_female", "pct_female",
"count_male", "pct_male")]
#Great, we've converted the columns to numeric, right?
#  No, not quite. We have done the calculation,
#  but we haven't _assigned_ the output to anything.
#  To do that, we need := again.
num_cols <- c("count_female", "pct_female",
"count_male", "pct_male")
#**NOTE** we have to surround num_cols on the left with
#  parentheses so that data.table knows we're not
#  trying to create a column called num_cols.
school_gender[ , (num_cols) := lapply(.SD, as.numeric),
.SDcols = num_cols]
print(school_gender, class = TRUE)
school_gender[total_enrolled - count_female - count_male != 0]
